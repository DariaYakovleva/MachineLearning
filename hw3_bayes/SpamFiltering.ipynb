{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(15000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 15 seconds\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 5\n",
    "%autosave 15\n",
    "\n",
    "import operator\n",
    "import functools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from collections import defaultdict\n",
    "from math import log\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"D:/Users/Daria/Code2/MachineLearning/hw3_bayes/Bayes/pu1/part\"\n",
    "SPAM = \"spam\"\n",
    "LEGIT = \"legit\"\n",
    "def getFiles(folderNumber):\n",
    "    curPath = path + str(folderNumber)\n",
    "    files = []\n",
    "    for filename in os.listdir(curPath):\n",
    "        file = open(curPath + \"/\" + filename, 'r')\n",
    "        subject = list(map(int, file.readline().split()[1:]))\n",
    "        file.readline()\n",
    "        text = list(map(int, file.readline().split()))\n",
    "        if LEGIT in filename:\n",
    "            files.append((LEGIT, [subject, text]))\n",
    "        else:\n",
    "            files.append((SPAM, [subject, text]))\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def training(trains):\n",
    "    frequencies = defaultdict(lambda:0)\n",
    "    classes = defaultdict(lambda:0)\n",
    "    counts = defaultdict(lambda:0)\n",
    "    for clazz, file in trains:\n",
    "        for word in file[1]:\n",
    "            # count files, not words???\n",
    "            frequencies[clazz, word] += 1.0\n",
    "            counts[word] += 1.0\n",
    "        classes[clazz] += len(file[1])\n",
    "    for clazz, word in frequencies:\n",
    "        frequencies[clazz, word] /= counts[word]\n",
    "        # можно размытие по лапласу, как будто каждо слово видели на 1 раз больше\n",
    "#         frequencies[clazz, word] = (frequencies[clazz, word] + 1.0) / (1.0 + counts[word])\n",
    "\n",
    "    for clazz in classes:\n",
    "        classes[clazz] /= len(trains)\n",
    "    return classes, frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainingSubj(trains):\n",
    "    frequencies = defaultdict(lambda:0)\n",
    "    classes = defaultdict(lambda:0)\n",
    "    counts = defaultdict(lambda:0)\n",
    "    for clazz, file in trains:\n",
    "        for word in file[0]:\n",
    "            frequencies[clazz, word] += 1.0\n",
    "            counts[word] += 1.0\n",
    "        for word in file[1]:\n",
    "            frequencies[clazz, word] += 1.0\n",
    "            counts[word] += 1.0\n",
    "        classes[clazz] += len(file[1]) + len(file[0])\n",
    "    for clazz, word in frequencies:\n",
    "        frequencies[clazz, word] /= counts[word]\n",
    "    for clazz in classes:\n",
    "        classes[clazz] /= len(trains)\n",
    "    return classes, frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errorWeight = defaultdict(lambda:1)\n",
    "errorWeight[SPAM] = 1\n",
    "errorWeight[LEGIT] = 1\n",
    "def classify(classifier, file):\n",
    "    classes, frequencies = classifier\n",
    "    #P(C|o_1..o_n) = P(c)*prod(P(o_i|c)\n",
    "    # result class = argmax(c, P(c)*prod(P(o_i|c))) = argmin(c, -log(P(c) - sum(log(P(o_i|c)))))\n",
    "    spamProb = -log(classes[SPAM])\n",
    "    legitProb = -log(classes[LEGIT])\n",
    "    for word in file[1]:\n",
    "        spamProb -= log(frequencies[SPAM, word] + 10 ** (-7))\n",
    "        legitProb -= log(frequencies[LEGIT, word] + 10 ** (-7))\n",
    "    spamProb -= log(errorWeight[SPAM])\n",
    "    legitProb -= log(errorWeight[LEGIT])\n",
    "    if (abs(spamProb - legitProb) < 20):\n",
    "        return LEGIT\n",
    "    if (spamProb < legitProb):\n",
    "        return SPAM\n",
    "    return LEGIT\n",
    "#     return min(classes.keys(), key = lambda clazz: -log(classes[clazz]) -\n",
    "#                sum(log(frequencies[clazz, word] + 10 ** (-7)) for word in file[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error =  0.00366972477064\n",
      "f1 score =  0.995824634656\n",
      "test count =  1090\n",
      "SPAM is SPAM =  609\n",
      "SPAM is LEGIT =  3\n",
      "LEGIT is SPAM =  1\n",
      "LEGIT is LEGIT =  477\n"
     ]
    }
   ],
   "source": [
    "folds = [getFiles(i) for i in range(1, 11)]\n",
    "meanClassifier = defaultdict(lambda:0), defaultdict(lambda:0)\n",
    "for trains in folds:\n",
    "    curClassifier = training(trains)\n",
    "    meanClassifier = getMeanClassifier(curClassifier, meanClassifier)\n",
    "predict = []\n",
    "answer = []\n",
    "counts = [[0, 0], [0, 0]]\n",
    "cnt = 0\n",
    "for test in folds:\n",
    "    for clazz, file in test:\n",
    "        predClass = classify(meanClassifier, file)\n",
    "        predict.append(int(predClass == SPAM))\n",
    "        answer.append(int(clazz == SPAM))\n",
    "        counts[predClass == SPAM][clazz == SPAM] += 1\n",
    "        cnt += 1\n",
    "print(\"mean squared error = \", mean_squared_error(predict, answer))\n",
    "print(\"f1 score = \", f1_score(predict, answer))\n",
    "print(\"test count = \", cnt)\n",
    "print(\"SPAM is SPAM = \", counts[0][0])\n",
    "print(\"SPAM is LEGIT = \", counts[0][1])\n",
    "print(\"LEGIT is SPAM = \", counts[1][0])\n",
    "print(\"LEGIT is LEGIT = \", counts[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMeanClassifier(classifier1, classifier2):\n",
    "    curClasses, curFrequencies = classifier1\n",
    "    meanClasses, meanFrequencies = classifier2\n",
    "    for clazz in curClasses:\n",
    "        meanClasses[clazz] = (meanClasses[clazz] + curClasses[clazz]) / 2\n",
    "    for clazz, word in curFrequencies:\n",
    "        meanFrequencies[clazz, word] = (meanFrequencies[clazz, word] + curFrequencies[clazz, word]) / 2\n",
    "    return meanClasses, meanFrequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training on subject\n",
    "mean squared error =  0.361467889908\n",
    "f1 score =  0.679674796748\n",
    "bad =  332  from  1090 ;  0.30458715596330277 %\n",
    "====\n",
    "training on text\n",
    "mean squared error =  0.00275229357798\n",
    "f1 score =  0.996884735202\n",
    "test count =  1090\n",
    "SPAM is SPAM =  607\n",
    "SPAM is LEGIT =  0\n",
    "LEGIT is SPAM =  3\n",
    "LEGIT is LEGIT =  480\n",
    "====\n",
    "training on text with laplas\n",
    "mean squared error =  0.00275229357798\n",
    "f1 score =  0.996884735202\n",
    "test count =  1090\n",
    "SPAM is SPAM =  607\n",
    "SPAM is LEGIT =  0\n",
    "LEGIT is SPAM =  3\n",
    "LEGIT is LEGIT =  480\n",
    "====\n",
    "< 20\n",
    "mean squared error =  0.00366972477064\n",
    "f1 score =  0.995824634656\n",
    "test count =  1090\n",
    "SPAM is SPAM =  609\n",
    "SPAM is LEGIT =  3\n",
    "LEGIT is SPAM =  1\n",
    "LEGIT is LEGIT =  477\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
